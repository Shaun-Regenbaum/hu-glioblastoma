{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment and annotation: \n",
    "Human glioblastoma tumors single nucleus transcripts were retrieved from Gene Expression Omnibus (GEO), with identifier GSE174554. Organoid and human glioblastoma transcripts were aligned and annotated using the NF-Core scrnaseq pipeline and the Cell Ranger mkref and mkgtf functions using the GRCh38.p14 reference genome sequence (fasta) and gene annotations (gtf). Raw sequencing reads underwent quality control using FastQC. Gene-level (counts) were quantified using Cell Ranger count. The resulting count matrix was converted into an H5AD file format (Scanpy compatible), and quality control metrics were collected by MultiQC.\n",
    "\n",
    "The following steps take in these .h5 files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n",
    "Initial setup for our required packages and setting how verbose our errors should be.\n",
    "During install, you may need to use ```pip``` rather thna ```pip3```, depends on how python is installed on your system (and what verions you have).\n",
    "\n",
    "Also, we are suppressing some terminal output using ```grep``` (so the output looks a little cleaner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting leidenalg\n",
      "  Downloading leidenalg-0.10.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Downloading leidenalg-0.10.2-cp38-abi3-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: leidenalg\n",
      "Successfully installed leidenalg-0.10.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaunie/Desktop/hu-glioblastoma/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.9.6 anndata==0.10.4 umap==0.5.5 numpy==1.26.3 scipy==1.11.4 pandas==2.1.4 scikit-learn==1.3.2 statsmodels==0.14.1 igraph==0.10.8 louvain==0.8.1 pynndescent==0.5.11\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy | grep -v 'already satisfied'\n",
    "!pip3 install pandas | grep -v 'already satisfied'\n",
    "!pip3 install seaborn | grep -v 'already satisfied'\n",
    "!pip3 install scanpy | grep -v 'already satisfied'\n",
    "!pip3 install leidenalg | grep -v 'Requirement already satisfied'\n",
    "!pip3 install louvain | grep -v 'Requirement already satisfied'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "\n",
    "sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aprrox. 1 sec per read\n",
    "file_location = ''\n",
    "data_1914 = '1914/1914_filtered.h5'\n",
    "data_1914d = '1914d/1914d_filtered.h5'\n",
    "data_1919 = '1919/1919_filtered.h5'\n",
    "data_1919d = '1919d/1919d_filtered.h5'\n",
    "\n",
    "# For remote server\n",
    "# file_location = '../datasets/'\n",
    "\n",
    "adata_1914_human = sc.read_10x_h5(\n",
    "    file_location + data_1914,\n",
    "    genome='GRCh38')\n",
    "adata_1914d_human = sc.read_10x_h5(\n",
    "    file_location + data_1914d,\n",
    "    genome='GRCh38')\n",
    "adata_1919_human = sc.read_10x_h5(\n",
    "    file_location + data_1919,\n",
    "    genome='GRCh38')\n",
    "adata_1919d_human = sc.read_10x_h5(\n",
    "    file_location + data_1919d,\n",
    "    genome='GRCh38')\n",
    "\n",
    "adata_1914_rat = sc.read_10x_h5(\n",
    "    file_location + data_1914,\n",
    "        genome='mRatBN7.2')\n",
    "adata_1914d_rat = sc.read_10x_h5(\n",
    "    file_location + data_1914d,\n",
    "    genome='mRatBN7.2')\n",
    "adata_1919_rat = sc.read_10x_h5(\n",
    "    file_location + data_1919,\n",
    "    genome='mRatBN7.2')\n",
    "adata_1919d_rat = sc.read_10x_h5(\n",
    "    file_location + data_1919d,\n",
    "    genome='mRatBN7.2')\n",
    "\n",
    "# View the first 5 rows of the data\n",
    "adata_1914_human.var.head()\n",
    "adata_1914_human.obs.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "We see that everything is either prepended by ```GRCh38____``` or ```mRatBN7.2_```. \n",
    "Thankfully, it seems that whoever did the previous analysis made sure these prepended labels were always ten charecters by adding underscores, so we can just strip the first ten charecters off all the gene_ids.\n",
    "\n",
    "The first thing we are going to do is strip the first ten charecters from all the gene_ids. \n",
    "\n",
    "Then we are going to ensure that all the gene_ids are unique in the respective datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adata_1914_human' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# filter the GRCh38__ from the front of names\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m adata_1914_human\u001b[38;5;241m.\u001b[39mvar_names \u001b[38;5;241m=\u001b[39m [name[\u001b[38;5;241m10\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43madata_1914_human\u001b[49m\u001b[38;5;241m.\u001b[39mvar_names]\n",
      "\u001b[1;32m      3\u001b[0m adata_1914d_human\u001b[38;5;241m.\u001b[39mvar_names \u001b[38;5;241m=\u001b[39m [name[\u001b[38;5;241m10\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m adata_1914d_human\u001b[38;5;241m.\u001b[39mvar_names]\n",
      "\u001b[1;32m      4\u001b[0m adata_1919_human\u001b[38;5;241m.\u001b[39mvar_names \u001b[38;5;241m=\u001b[39m [name[\u001b[38;5;241m10\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m adata_1919_human\u001b[38;5;241m.\u001b[39mvar_names]\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adata_1914_human' is not defined"
     ]
    }
   ],
   "source": [
    "# filter the GRCh38__ from the front of names\n",
    "adata_1914_human.var_names = [name[10:] for name in adata_1914_human.var_names]\n",
    "adata_1914d_human.var_names = [name[10:] for name in adata_1914d_human.var_names]\n",
    "adata_1919_human.var_names = [name[10:] for name in adata_1919_human.var_names]\n",
    "adata_1919d_human.var_names = [name[10:] for name in adata_1919d_human.var_names]\n",
    "adata_1914_rat.var_names = [name[10:] for name in adata_1914_rat.var_names]\n",
    "adata_1914d_rat.var_names = [name[10:] for name in adata_1914d_rat.var_names]\n",
    "adata_1919_rat.var_names = [name[10:] for name in adata_1919_rat.var_names]\n",
    "adata_1919d_rat.var_names = [name[10:] for name in adata_1919d_rat.var_names]\n",
    "\n",
    "\n",
    "# make the gene names unique\n",
    "adata_1914_human.var_names_make_unique()\n",
    "adata_1914d_human.var_names_make_unique()\n",
    "adata_1919_human.var_names_make_unique()\n",
    "adata_1919d_human.var_names_make_unique()\n",
    "adata_1914_rat.var_names_make_unique()\n",
    "adata_1914d_rat.var_names_make_unique()\n",
    "adata_1919_rat.var_names_make_unique()\n",
    "adata_1919d_rat.var_names_make_unique()\n",
    "\n",
    "adata_combined = adata_1914_human.concatenate(adata_1914_rat, adata_1914d_human, adata_1914d_rat, adata_1919_human, adata_1919_rat, adata_1919d_human, adata_1919d_rat, batch_categories=['1914_human', '1914_rat', '1914d_human', '1914d_rat', '1919_human', '1919_rat', '1919d_human', '1919d_rat'], join='outer')\n",
    "\n",
    "adata_human_combined = adata_1914_human.concatenate(adata_1914d_human, adata_1919_human, adata_1919d_human, batch_categories=['1914_human', '1914d_human', '1919_human', '1919d_human'], join='outer')\n",
    "\n",
    "adata_human_combined.obs.batch.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_total_combined = 'final_data/total_combined.h5ad'\n",
    "rf_human_combined = 'final_data/human_combined.h5ad'\n",
    "\n",
    "running_on = [adata_combined, adata_human_combined]\n",
    "saving_to = [rf_total_combined, rf_human_combined]\n",
    "\n",
    "# We want to quickly write everything to our results files:\n",
    "def write_results(running_on, saving_to):\n",
    "    for i in range(len(running_on)):\n",
    "        running_on[i].write(saving_to[i])\n",
    "        print('Wrote to ' + saving_to[i])\n",
    "        \n",
    "write_results(running_on, saving_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "1) Filter any cells that have less than 200 genes expressed.\n",
    "2) Filter any genes that are expressed in less than 2 cells.\n",
    "3) Annotating any known mitochondrial genes, as they introduce unncessary noise.\n",
    "4) Filter out any cells with more than 2500 genes.\n",
    "5) Filter out any cells of which more than 5% of their genes are mitochondrial.\n",
    "\n",
    "We are also computing QC metrics that we will use throughout. These include:\n",
    "1) total_genes_by_count: single number for how many genes are present in a cell.\n",
    "2) n_genes_by_count: single number for the number of genes with at least 1 count in a cell.\n",
    "3) total_counts: a single number for the total amount of counts expressed by every gene in a cell.\n",
    "4) pct_counts_mt: The proportion of total counts for a cell which are from mitochondrial genes.\n",
    "\n",
    "There are others, but are not important for now...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filter cells with less than 200 genes expressed\n",
    "def filter_200(running_on):\n",
    "    for item in running_on:\n",
    "        sc.pp.filter_cells(item, min_genes=200)\n",
    "    \n",
    "# filter genes expressed in less than 2 cells\n",
    "def filter_2(running_on):\n",
    "    for item in running_on:\n",
    "        sc.pp.filter_genes(item, min_cells=2)\n",
    "        \n",
    "# annotate the group of mitochondrial genes as 'mt'\n",
    "def annotate_mt(running_on):\n",
    "    for item in running_on:\n",
    "        item.var['mt'] = item.var_names.str.startswith('MT-')\n",
    "# compute QC metrics for all datasets\n",
    "def qc_metrics(running_on):\n",
    "    for item in running_on:\n",
    "        sc.pp.calculate_qc_metrics(item, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "\n",
    "# filter cells with more than 2500 genes\n",
    "def filter_2500(running_on):\n",
    "    for item in running_on:\n",
    "        item = item[item.obs.n_genes_by_counts < 2500, :]\n",
    "\n",
    "# filter cells with more than 5% mitochondrial genes\n",
    "def filter_5_mt(running_on):\n",
    "    for item in running_on:\n",
    "        item = item[item.obs.pct_counts_mt < 5, :]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aprrox. 2.5 sec per group\n",
    "filter_200(running_on)\n",
    "\n",
    "# Aprrox. 0.5 sec per group\n",
    "filter_2(running_on)\n",
    "\n",
    "\n",
    "# Aprrox. 0.5 sec per group\n",
    "annotate_mt(running_on)\n",
    "\n",
    "# Aprrox. 0.5 sec per group\n",
    "qc_metrics(running_on)\n",
    "\n",
    "# Aprrox. 0.5 sec per group\n",
    "filter_2500(running_on)\n",
    "\n",
    "# Aprrox. 0.5 sec per group\n",
    "filter_5_mt(running_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.jointplot(\n",
    "        data=adata_combined.obs,\n",
    "        x=\"total_counts\",\n",
    "        y=\"n_genes_by_counts\",\n",
    "        kind=\"hex\",\n",
    "    )\n",
    "\n",
    "sns.histplot(adata_human_combined.obs[\"pct_counts_mt\"])\n",
    "\n",
    "sc.pl.violin(adata_combined, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],\n",
    "                jitter=0.4, multi_panel=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "It is important to normalize our data. Since we are combining different datasets and have done some filtering, we want to make sure that no genes or cells are over represented. Therefore we going to normalize on a per cell basis by essentially dividing all gene counts by the total count data for every cell. \n",
    "\n",
    "We will also put them on a log basis to make visualization easier. Just note this for future visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "def normalize_data(running_on):\n",
    "    for item in running_on:\n",
    "        sc.pp.normalize_total(item, target_sum=1e4)\n",
    "\n",
    "# Putting on a log scale\n",
    "def log1p(running_on):\n",
    "    for item in running_on:\n",
    "        sc.pp.log1p(item)\n",
    "\n",
    "def variablize(running_on):\n",
    "    for item in running_on:\n",
    "        sc.pp.highly_variable_genes(item, min_mean=0.0125, min_disp=0.5, batch_key='batch')\n",
    "\n",
    "def save_raw(running_on):\n",
    "    for item in running_on:\n",
    "        item.raw = item\n",
    "\n",
    "def filter_highly_variable(running_on):\n",
    "    for item in running_on:\n",
    "        item = item[:, item.var.highly_variable]\n",
    "\n",
    "def dedensify(running_on):\n",
    "    for item in running_on:\n",
    "        # remove random cells\n",
    "        item = item[np.random.choice(item.shape[0], 10000, replace=False), :]\n",
    "        \n",
    "def regress_out(running_on):\n",
    "    for item in running_on:\n",
    "        sc.pp.regress_out(item, ['total_counts', 'pct_counts_mt'])\n",
    "        \n",
    "def scale_data(running_on, max=10):\n",
    "    for item in running_on:\n",
    "        sc.pp.scale(item, max_value=max)\n",
    "\n",
    "def batch_correct(running_on):\n",
    "    for item in running_on:\n",
    "        sc.pp.combat(item, key='batch', inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aprrox. 0.5 sec per group\n",
    "normalize_data(running_on)\n",
    "\n",
    "# Aprrox. 0.5 sec per group\n",
    "log1p(running_on)\n",
    "\n",
    "variablize(running_on)\n",
    "\n",
    "# Aprrox. 0.1 sec per group\n",
    "save_raw(running_on)\n",
    "\n",
    "# Aprrox. 0.5 sec per group\n",
    "filter_highly_variable(running_on)\n",
    "\n",
    "dedensify(running_on)\n",
    "\n",
    "# If you don't dedensify, this regression will take a long time\n",
    "regress_out(running_on)\n",
    "\n",
    "# Aprrox. 1 sec per group\n",
    "scale_data(running_on)\n",
    "\n",
    "batch_correct(running_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations, Dimensional Reducations, and Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pca(running_on):\n",
    "    for item in running_on:\n",
    "        sc.tl.pca(item, svd_solver='arpack')\n",
    "\n",
    "def do_nearest_neighbour(running_on):\n",
    "    for item in running_on:\n",
    "        sc.pp.neighbors(item, n_neighbors=40, n_pcs=20)\n",
    "        \n",
    "def do_leiden(running_on):\n",
    "    for item in running_on:\n",
    "        sc.tl.leiden(item)\n",
    "        \n",
    "def do_louvain(running_on):\n",
    "    for item in running_on:\n",
    "        sc.tl.louvain(item)\n",
    "        \n",
    "\n",
    "def do_paga(running_on):\n",
    "    for item in running_on:\n",
    "        sc.tl.paga(item)\n",
    "        sc.pl.paga(item, plot=True)\n",
    "         \n",
    "def do_umap(running_on):\n",
    "    for item in running_on:\n",
    "      sc.tl.umap(item, spread=0.5, min_dist=0.4)\n",
    "    \n",
    "def do_tsne(running_on):\n",
    "    for item in running_on:\n",
    "        sc.tl.tsne(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick visualisation of the highly variable genes\n",
    "sc.pl.highly_variable_genes(adata_combined)\n",
    "\n",
    "# Aprrox. 40 sec per group\n",
    "do_pca(running_on)\n",
    "\n",
    "# plotting pca, we should use color...\n",
    "sc.pl.pca(adata_human_combined, color='batch')\n",
    "\n",
    "# Taking a look at how impactful each principal component is\n",
    "sc.pl.pca_variance_ratio(adata_combined, log=True)\n",
    "\n",
    "write_results(running_on, saving_to) \n",
    "\n",
    "# Aprrox. 10 sec per group\n",
    "do_nearest_neighbour(running_on)\n",
    "\n",
    "# Aprrox. 5 sec per group\n",
    "do_leiden(running_on)\n",
    "\n",
    "do_louvain(running_on)\n",
    "\n",
    "# Aprrox. 0.5 sec per group\n",
    "do_paga(running_on)\n",
    "\n",
    "# Aprrox. 15 sec per group\n",
    "do_umap(running_on)\n",
    "\n",
    "use_raw = False\n",
    "color = ['louvain']\n",
    "sc.pl.umap(adata_human_combined, color=color, use_raw=use_raw)\n",
    "\n",
    "# Aprrox. 1.5 minutes per group\n",
    "do_tsne(running_on)\n",
    "\n",
    "use_raw = False\n",
    "color = ['louvain']\n",
    "\n",
    "# plotting tsne\n",
    "sc.pl.tsne(adata_human_combined, color=color, use_raw=use_raw)\n",
    "\n",
    "write_results(running_on, saving_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_genes = 25\n",
    "method = \"t-test\" # an alternative to try is wilconxon\n",
    "\n",
    "def rank_gene_groups(running_on):\n",
    "    for item in running_on:\n",
    "        sc.tl.rank_genes_groups(item, 'leiden', method=method)\n",
    "        sc.pl.rank_genes_groups(item, n_genes=number_of_genes, sharey=False, pts=True)\n",
    "\n",
    "# Aprrox. 10 sec per group\n",
    "rank_gene_groups(running_on)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
